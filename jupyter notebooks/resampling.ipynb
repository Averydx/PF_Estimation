{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Numpy Choice Algorithm</center> ###\n",
    "\n",
    "\n",
    "\n",
    "Numpy's choice algorithm is defined in the source file \"_generator.pyx\", and is an element of the Generator class returned when calling default_rng(). Note that generator can be instantiated manually, and wraps a numpy bit_generator, which is a prng, i.e. PCG64, mt19337, etc. \n",
    "\n",
    "The default prng is PCG64, which is significantly faster than mt19337 and passes more statistical tests, so there is no reason to deviate in our use case. \n",
    "\n",
    "$ CDF = \\begin{bmatrix}\n",
    "           w_{0} \\\\\n",
    "           w_{0}+w{1} \\\\\n",
    "           \\vdots \\\\\n",
    "           w_{0}+...+w_{n-1}\n",
    "         \\end{bmatrix} $\n",
    "\n",
    "\n",
    "where $\\sum_{i=0}^{n-1}w_{i} = 1 $\n",
    "\n",
    "and the final element of the CDF is 1.\n",
    "\n",
    "The algorithm that numpy uses is referred to in the literature as multinomial resampling, where samples are drawn independently on the interval\n",
    "$ u_i = [0,1) $ and $i$ between $0$ and $n-1$.\n",
    "\n",
    "so $ U =  \\begin{bmatrix}\n",
    "           u_{0} \\\\\n",
    "           u_1 \\\\\n",
    "           \\vdots \\\\\n",
    "           u_{i}\n",
    "         \\end{bmatrix} $\n",
    "\n",
    "We then take all the samples and evaluate at which index in $CDF$ they could be inserted while maintaining order, \n",
    "this is the function cdf.searchsorted(uniform_samples) which is a binary search implementation which returns a vector of \n",
    "indices. This resampling algorithm will have a time complexity of $O(nlogn)$ as the $logn$ binary search must be run over every sample.\n",
    "\n",
    "![Alt text](image.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices drawn from numpy choice: [8 2 6 7 8 9 0 7 0 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "gen = np.random.default_rng(10)\n",
    "orig_weights = np.array([gen.random() for _ in range(10)])\n",
    "orig_weights /= np.sum(orig_weights)\n",
    "\n",
    "numpy_weights = np.copy(orig_weights)\n",
    "numpy_weights /= np.sum(numpy_weights)\n",
    "\n",
    "'''The numpy resampling algorithm as defined in numpy.random.Generator.choice, generates N random samples from a uniform distribution (0,1)\n",
    "and performs a binary search to obtain the index in the sorted CDF where the samples would be inserted to maintain order\n",
    "\n",
    "Time complexity O(nlogn) where n is the number of samples, in our case n = len(weights)\n",
    "\n",
    "https://github.com/numpy/numpy/blob/64fc516a0fce06169a1e0fea55c7cd2dc57cd296/numpy/random/_generator.pyx#L3084\n",
    "'''\n",
    "def numpy_choice(weights): \n",
    "    cdf = weights.cumsum() #cumulative sum stored in np.array\n",
    "    cdf /= cdf[-1] #normalization done in function\n",
    "    uniform_samples = gen.random(weights.shape)\n",
    "    idx = cdf.searchsorted(uniform_samples, side='right') #a binary search over the array\n",
    "    return idx\n",
    "idx=numpy_choice(numpy_weights)\n",
    "print(f\"indices drawn from numpy choice: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> The Systematic Resampling Algorithm  ###\n",
    "\n",
    "Another approach to resampling is the systematic resampling algorithm, this algorithm is faster than the multinomial algorithm and it can be shown that it preserves a greater number of samples from \n",
    "the original weight distribution.\n",
    "\n",
    "We first construct the cdf in the same manner as above. \n",
    "\n",
    "$ CDF = \\begin{bmatrix}\n",
    "           w_{0} \\\\\n",
    "           w_{0}+w{1} \\\\\n",
    "           \\vdots \\\\\n",
    "           w_{0}+...+w_{n-1}\n",
    "         \\end{bmatrix} $\n",
    "\n",
    "\n",
    "where $\\sum_{i=0}^{n-1}w_{i} = 1 $\n",
    "\n",
    "and the final element of the CDF is 1.\n",
    "\n",
    "We then draw a random number $ u = [0,\\frac{1}{len(weights)})$. \n",
    "\n",
    "Now we can iterate over the $CDF$ and compare the value of $r$ to $CDF[i]$ where $r = (u + 1/len(weights)*j) $\n",
    "\n",
    "and $i,j$ are iterators. If the while loop passes r then we stop incrementation of $i$ and record the index at which i landed.\n",
    "\n",
    "This algorithm has a time complexity of $O(n)$ as we only iterate over the $CDF$ once\n",
    "\n",
    "\n",
    "A slightly different but functionally equivalent formulation:\n",
    "\n",
    "![Alt text](image-2.png)\n",
    "\n",
    "\n",
    "![Alt text](image-1.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices drawn from systematic resampling: [0. 0. 2. 2. 4. 6. 7. 7. 8. 9.]\n"
     ]
    }
   ],
   "source": [
    "'''The systematic resampling algorithm uses a slightly different approach, assuming that we are drawing n samples where n=len(weights),\n",
    "numpy cannot assume this as it supports drawing fewer samples than len(weights). \n",
    "\n",
    "We draw only 1 random sample u=U(1/n) as offset the subsequent n-1 indices by u +(1/n)*j, this has multiple advantages, firstly, if the weights are\n",
    "uniform the indices will not change, secondly, the time complexity is only O(n) as no search step is required\n",
    "\n",
    "Note also that the indices and resampled in sorted order, although for our case this doesn't matter, it's worth noting \n",
    "'''\n",
    "systematic_weights = np.copy(orig_weights)\n",
    "systematic_weights /= np.sum(systematic_weights)\n",
    "\n",
    "def systematic_choice(weights): \n",
    "    indices = np.zeros(len(weights)) #initialize array to hold the indices\n",
    "    cdf = np.cumsum(weights) #create cdf\n",
    "    u = gen.uniform(0,1/len(weights)) #random number between 1 and 1/n, only drawn once vs the n \n",
    "    i=0\n",
    "    for j in range(0,len(weights)): \n",
    "        r = (u + 1/len(weights) * j)\n",
    "        while r > cdf[i]: \n",
    "            i += 1\n",
    "        indices[j] = i\n",
    "    return indices\n",
    "indices = systematic_choice(systematic_weights)\n",
    "print(f\"indices drawn from systematic resampling: {indices}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Resampling in the Log-Domain ###\n",
    "\n",
    "While systematic resampling can be easily performed in the log domain, we require a special function to normalize the weights and compute the log-CDF, the Jacobian Logarithm as defined below.\n",
    "\n",
    "![Alt text](image-3.png)\n",
    "\n",
    "We can calculate the Jacobian Logarithm iteratively using: \n",
    "\n",
    "![Alt text](image-4.png)\n",
    "\n",
    "This will allow us to normalize our weights and compute the $CDF$ in the log domain.\n",
    "\n",
    "![Alt text](image-5.png)\n",
    "\n",
    "Now we can calculate the log-CDF and perform systematic resampling in the log domain: \n",
    "\n",
    "![Alt text](image-6.png)\n",
    "\n",
    "However in python we must index from $0$ to $n-1$ as opposed to $1$ to $n$.\n",
    "Also note that if j = 1, then is assigned $[u]_1 = ln([u]_1) $\n",
    "\n",
    "I believe this is a notational error as we don't want $[u]_1$ to be on the log scale or a negative number. Then on subsequent passes of $j$ the indices are \n",
    "returned as $NaN$ and only index $0$ is sampled. \n",
    "\n",
    "I have fixed this error in the code below, I don't hold the vector of $[u]$ and just hold the current value, as the whole vector is never called back on or queried. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices drawn from log systematic resampling: [0. 1. 2. 4. 5. 6. 7. 8. 9. 9.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "'''The jacobian logarithm, used in log likelihood normalization and resampling processes\n",
    "δ will be an array of log-probabilities '''\n",
    "def jacob(δ):\n",
    "    n = len(δ)\n",
    "    Δ = np.zeros(n)\n",
    "    Δ[0] = δ[0]\n",
    "    for i in range(1,n):\n",
    "        Δ[i] = max(δ[i],Δ[i-1]) + np.log(1 + np.exp(-1*np.abs(δ[i] - Δ[i-1])))\n",
    "    return(Δ)\n",
    "\n",
    "'''normalizes the probability space using the jacobian logarithm as defined in jacob() '''\n",
    "def log_norm(log_weights): \n",
    "    norm = (jacob(log_weights)[-1])\n",
    "    log_weights -= norm\n",
    "    return log_weights\n",
    "\n",
    "\n",
    "'''The systematic resampling in log domain is functionally equivalent to doing so in the lin-domain, but requires a special helper function, \n",
    "the jacobian logarithm, i.e. log(sum(exp(x1)+exp(x2) + ... + exp(xn)))'''\n",
    "\n",
    "\n",
    "def log_systematic(weights): \n",
    "    log_weights = np.copy(weights)\n",
    "    log_weights = np.log(log_weights)\n",
    "    log_weights = log_norm(log_weights) \n",
    "\n",
    "    log_cdf = jacob(log_weights) #construct log_cdf using the jacobian log\n",
    "            \n",
    "    i = 0\n",
    "    indices = np.zeros(len(log_weights))\n",
    "    u = gen.uniform(0,1/len(log_weights))\n",
    "    for j in range(0,len(log_weights)): \n",
    "        r = np.log(u + 1/len(log_weights) * j)\n",
    "        while r > log_cdf[i]: \n",
    "            i += 1\n",
    "        indices[j] = i\n",
    "\n",
    "    return indices\n",
    "\n",
    "indices = log_systematic(orig_weights)\n",
    "\n",
    "print(f\"indices drawn from log systematic resampling: {indices}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Benchmarking and Numerical Tests ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test weights: [0.13564954 0.00497478 0.07336354 0.15430598 0.18229279 0.08201341\n",
      " 0.17393443 0.04658767 0.03520282 0.11167503]\n",
      "\n",
      "numpy run time for 1000 samples: 0.005590458051301539\n",
      "differences: [0.00084954 0.00022522 0.00283646 0.00189402 0.00130721 0.00011341\n",
      " 0.00713443 0.00251233 0.00110282 0.00042497]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "systematic resampling run time for 1000 samples: 0.007432041922584176\n",
      "differences: [5.04593344e-05 1.07477505e-03 2.03646080e-03 3.94016083e-04\n",
      " 3.69279459e-03 2.28658728e-03 1.16557027e-03 2.78767365e-03\n",
      " 1.69717709e-03 7.50275684e-05]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "systematic log resampling run time for 1000 samples: 0.0577617910457775\n",
      "differences: [0.00084954 0.00022522 0.00283646 0.00189402 0.00130721 0.00011341\n",
      " 0.00713443 0.00251233 0.00110282 0.00042497]\n"
     ]
    }
   ],
   "source": [
    "from time import perf_counter\n",
    "\n",
    "test_weights = np.array([gen.random() for _ in range(10)])\n",
    "test_weights /= np.sum(test_weights)\n",
    "print(f\"test weights: {test_weights}\\n\")\n",
    "\n",
    "t1 = perf_counter()\n",
    "all_samples_numpy = np.array([numpy_choice(test_weights) for _ in range(1000)])\n",
    "t2 = perf_counter()\n",
    "\n",
    "print(f\"numpy run time for 1000 samples: {t2-t1}\")\n",
    "\n",
    "all_samples_numpy = all_samples_numpy.flatten()\n",
    "all_samples_numpy= np.sort(all_samples_numpy)\n",
    "\n",
    "sample_count_numpy = []\n",
    "for i in range(0,10): \n",
    "    sample_count_numpy.append(np.count_nonzero(all_samples_numpy == i)/len(all_samples_numpy))\n",
    "    #print(f\"percentage of elements equal to {i} is {sample_count_numpy[-1]}, orignal weight:{orig_weights[i]}\")\n",
    "print(f\"differences: {np.abs(test_weights-sample_count_numpy)}\")\n",
    "\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "t3 = perf_counter()\n",
    "all_samples_systematic= np.array([systematic_choice(test_weights) for _ in range(1000)])\n",
    "t4 = perf_counter()\n",
    "\n",
    "print(f\"systematic resampling run time for 1000 samples: {t4-t3}\")\n",
    "\n",
    "all_samples_systematic = all_samples_systematic.flatten()\n",
    "all_samples_systematic= np.sort(all_samples_systematic)\n",
    "\n",
    "sample_count_systematic = []\n",
    "for i in range(0,10): \n",
    "    sample_count_systematic.append(np.count_nonzero(all_samples_systematic == i)/len(all_samples_systematic))\n",
    "    #print(f\"percentage of elements equal to {i} is {sample_count_systematic[-1]}, original weight:{test_weights[i]}\")\n",
    "print(f\"differences: {np.abs(test_weights-sample_count_systematic)}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n\\n\\n\")\n",
    "\n",
    "\n",
    "t5 = perf_counter()\n",
    "all_samples_log = np.array([log_systematic(test_weights) for _ in range(1000)])\n",
    "t6 = perf_counter()\n",
    "\n",
    "print(f\"systematic log resampling run time for 1000 samples: {t6-t5}\")\n",
    "\n",
    "all_samples_log = all_samples_log.flatten()\n",
    "all_samples_log= np.sort(all_samples_numpy)\n",
    "\n",
    "sample_count_log = []\n",
    "for i in range(0,10): \n",
    "    sample_count_log.append(np.count_nonzero(all_samples_log == i)/len(all_samples_log))\n",
    "    #print(f\"percentage of elements equal to {i} is {sample_count_log[-1]}, original weight:{test_weights[i]}\")\n",
    "print(f\"differences: {np.abs(test_weights-np.array(sample_count_log))}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
